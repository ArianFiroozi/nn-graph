// Attention Mechanism
digraph {
	rankdir=LR
	Input [label="Input (Q, K, V)" shape=box]
	DotProduct [label="Dot Product (Q.K^T)" shape=box]
	Scale [label="Scale by 1/sqrt(d_k)" shape=box]
	Softmax [label=Softmax shape=box]
	WeightedSum [label="Weighted Sum (Attention Output)" shape=box]
	Output [label=Output shape=box]
	Input -> DotProduct
	DotProduct -> Scale
	Scale -> Softmax
	Softmax -> WeightedSum
	WeightedSum -> Output
}
